{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./dataset/training_set_VU_DM.csv')\n",
    "test_set = pd.read_csv('./dataset/test_set_VU_DM.csv')\n",
    "\n",
    "train_set = train_set.drop(columns=[\"date_time\", \n",
    "                                    \"visitor_hist_starrating\", \n",
    "                                    \"visitor_hist_adr_usd\",\n",
    "                                    \"srch_query_affinity_score\",\n",
    "                                    \"orig_destination_distance\",\n",
    "                                    \"comp1_rate\", \"comp1_inv\", \"comp1_rate_percent_diff\",\n",
    "                                    \"comp2_rate\", \"comp2_inv\", \"comp2_rate_percent_diff\",\n",
    "                                    \"comp3_rate\", \"comp3_inv\", \"comp3_rate_percent_diff\",\n",
    "                                    \"comp4_rate\", \"comp4_inv\", \"comp4_rate_percent_diff\",\n",
    "                                    \"comp5_rate\", \"comp5_inv\", \"comp5_rate_percent_diff\",\n",
    "                                    \"comp6_rate\", \"comp6_inv\", \"comp6_rate_percent_diff\",\n",
    "                                    \"comp7_rate\", \"comp7_inv\", \"comp7_rate_percent_diff\",\n",
    "                                    \"comp8_rate\", \"comp8_inv\", \"comp8_rate_percent_diff\",\n",
    "                                    \"gross_bookings_usd\"])\n",
    "\n",
    "test_set = test_set.drop(columns=[\"date_time\", \n",
    "                                    \"visitor_hist_starrating\", \n",
    "                                    \"visitor_hist_adr_usd\",\n",
    "                                    \"srch_query_affinity_score\",\n",
    "                                    \"orig_destination_distance\",\n",
    "                                    \"comp1_rate\", \"comp1_inv\", \"comp1_rate_percent_diff\",\n",
    "                                    \"comp2_rate\", \"comp2_inv\", \"comp2_rate_percent_diff\",\n",
    "                                    \"comp3_rate\", \"comp3_inv\", \"comp3_rate_percent_diff\",\n",
    "                                    \"comp4_rate\", \"comp4_inv\", \"comp4_rate_percent_diff\",\n",
    "                                    \"comp5_rate\", \"comp5_inv\", \"comp5_rate_percent_diff\",\n",
    "                                    \"comp6_rate\", \"comp6_inv\", \"comp6_rate_percent_diff\",\n",
    "                                    \"comp7_rate\", \"comp7_inv\", \"comp7_rate_percent_diff\",\n",
    "                                    \"comp8_rate\", \"comp8_inv\", \"comp8_rate_percent_diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4958347, 22])\n",
      "torch.Size([4958347, 2])\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "train_set_Y = train_set[[\"click_bool\", \"booking_bool\"]]\n",
    "train_set_X = train_set.drop(columns=[\"click_bool\", \"booking_bool\"])\n",
    "\n",
    "X_array = np.array(train_set_X, dtype=np.float32)\n",
    "Y_array = np.array(train_set_Y, dtype=np.float32)\n",
    "\n",
    "X_tensor = torch.tensor(X_array)\n",
    "Y_tensor = torch.tensor(Y_array)\n",
    "\n",
    "X_tensor = torch.where(torch.isnan(X_tensor), torch.zeros_like(X_tensor), X_tensor)\n",
    "Y_tensor = torch.where(torch.isnan(Y_tensor), torch.zeros_like(Y_tensor), Y_tensor)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "\n",
    "train_size = int(0.75*len(X_tensor))\n",
    "test_size = len(X_tensor) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=500, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=500, shuffle=False)\n",
    "\n",
    "print(X_tensor.shape)\n",
    "print(Y_tensor.shape)\n",
    "\n",
    "in_size = X_tensor.size(dim=1)\n",
    "out_size = Y_tensor.size(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=22, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, nn, optimiser, loss_fn, train_loader, test_loader):\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: \"+str(epoch))\n",
    "        outputs_return = []\n",
    "        labels_return = []\n",
    "        for inputs, label in train_loader:\n",
    "            # Training mode\n",
    "            nn.train() \n",
    "            # Reset gradients\n",
    "            optimiser.zero_grad()\n",
    "            # Forward propagation\n",
    "            outputs = nn(inputs)\n",
    "            # Training loss\n",
    "            loss = loss_fn(outputs, label) \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            torch.nn.utils.clip_grad_norm_(nn.parameters(), max_norm=2)\n",
    "            optimiser.step() \n",
    "\n",
    "        # Evaluation mode\n",
    "        nn.eval() \n",
    "        # Disable gradient calc\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            # Compute classes and losses\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = nn(inputs)\n",
    "                outputs_return.append(outputs)\n",
    "                labels_return.append(labels)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(f\"Epoch: {epoch}, train loss: {loss.item():.5f}, test loss: {test_loss:.5f}\")\n",
    "            #print(\"Result std: \"+str(np.std(np.array((10-1)*y_test+1))))\n",
    "            #print(\"Prediction std: \"+str(np.std(np.array((10-1)*test_preds+1))))\n",
    "\n",
    "    return outputs_return, labels_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 0, train loss: 0.01231, test loss: 0.03512\n",
      "Epoch: 1\n",
      "Epoch: 1, train loss: 0.01191, test loss: 0.03511\n",
      "Epoch: 2\n",
      "Epoch: 2, train loss: 0.01218, test loss: 0.03511\n",
      "Epoch: 3\n",
      "Epoch: 3, train loss: 0.01197, test loss: 0.03511\n",
      "Epoch: 4\n",
      "Epoch: 4, train loss: 0.01230, test loss: 0.03512\n",
      "Epoch: 5\n",
      "Epoch: 5, train loss: 0.01213, test loss: 0.03511\n",
      "Epoch: 6\n",
      "Epoch: 6, train loss: 0.01167, test loss: 0.03519\n",
      "Epoch: 7\n",
      "Epoch: 7, train loss: 0.01177, test loss: 0.03514\n",
      "Epoch: 8\n",
      "Epoch: 8, train loss: 0.01203, test loss: 0.03510\n",
      "Epoch: 9\n",
      "Epoch: 9, train loss: 0.01209, test loss: 0.03510\n",
      "Epoch: 10\n",
      "Epoch: 10, train loss: 0.01196, test loss: 0.03511\n",
      "Epoch: 11\n",
      "Epoch: 11, train loss: 0.01240, test loss: 0.03514\n",
      "Epoch: 12\n",
      "Epoch: 12, train loss: 0.01192, test loss: 0.03511\n",
      "Epoch: 13\n",
      "Epoch: 13, train loss: 0.01211, test loss: 0.03510\n",
      "Epoch: 14\n",
      "Epoch: 14, train loss: 0.01216, test loss: 0.03511\n",
      "Epoch: 15\n",
      "Epoch: 15, train loss: 0.01207, test loss: 0.03510\n",
      "Epoch: 16\n",
      "Epoch: 16, train loss: 0.01187, test loss: 0.03512\n",
      "Epoch: 17\n",
      "Epoch: 17, train loss: 0.01230, test loss: 0.03512\n",
      "Epoch: 18\n",
      "Epoch: 18, train loss: 0.01199, test loss: 0.03511\n",
      "Epoch: 19\n",
      "Epoch: 19, train loss: 0.01189, test loss: 0.03512\n",
      "Epoch: 20\n",
      "Epoch: 20, train loss: 0.01182, test loss: 0.03513\n",
      "Epoch: 21\n",
      "Epoch: 21, train loss: 0.01206, test loss: 0.03510\n",
      "Epoch: 22\n",
      "Epoch: 22, train loss: 0.01181, test loss: 0.03514\n",
      "Epoch: 23\n",
      "Epoch: 23, train loss: 0.01196, test loss: 0.03511\n",
      "Epoch: 24\n",
      "Epoch: 24, train loss: 0.01180, test loss: 0.03514\n",
      "Epoch: 25\n",
      "Epoch: 25, train loss: 0.01231, test loss: 0.03515\n",
      "Epoch: 26\n",
      "Epoch: 26, train loss: 0.01197, test loss: 0.03510\n",
      "Epoch: 27\n",
      "Epoch: 27, train loss: 0.01193, test loss: 0.03511\n",
      "Epoch: 28\n",
      "Epoch: 28, train loss: 0.01169, test loss: 0.03517\n",
      "Epoch: 29\n",
      "Epoch: 29, train loss: 0.01219, test loss: 0.03511\n",
      "Epoch: 30\n",
      "Epoch: 30, train loss: 0.01282, test loss: 0.03524\n",
      "Epoch: 31\n",
      "Epoch: 31, train loss: 0.01188, test loss: 0.03511\n",
      "Epoch: 32\n",
      "Epoch: 32, train loss: 0.01191, test loss: 0.03511\n",
      "Epoch: 33\n",
      "Epoch: 33, train loss: 0.01213, test loss: 0.03511\n",
      "Epoch: 34\n",
      "Epoch: 34, train loss: 0.01189, test loss: 0.03512\n",
      "Epoch: 35\n",
      "Epoch: 35, train loss: 0.01255, test loss: 0.03517\n",
      "Epoch: 36\n",
      "Epoch: 36, train loss: 0.01177, test loss: 0.03515\n",
      "Epoch: 37\n",
      "Epoch: 37, train loss: 0.01190, test loss: 0.03511\n",
      "Epoch: 38\n",
      "Epoch: 38, train loss: 0.01222, test loss: 0.03512\n",
      "Epoch: 39\n",
      "Epoch: 39, train loss: 0.01181, test loss: 0.03513\n",
      "Epoch: 40\n",
      "Epoch: 40, train loss: 0.01202, test loss: 0.03511\n",
      "Epoch: 41\n",
      "Epoch: 41, train loss: 0.01219, test loss: 0.03511\n",
      "Epoch: 42\n",
      "Epoch: 42, train loss: 0.01192, test loss: 0.03511\n",
      "Epoch: 43\n",
      "Epoch: 43, train loss: 0.01206, test loss: 0.03510\n",
      "Epoch: 44\n",
      "Epoch: 44, train loss: 0.01202, test loss: 0.03511\n",
      "Epoch: 45\n",
      "Epoch: 45, train loss: 0.01173, test loss: 0.03516\n",
      "Epoch: 46\n",
      "Epoch: 46, train loss: 0.01219, test loss: 0.03511\n",
      "Epoch: 47\n",
      "Epoch: 47, train loss: 0.01224, test loss: 0.03511\n",
      "Epoch: 48\n",
      "Epoch: 48, train loss: 0.01207, test loss: 0.03510\n",
      "Epoch: 49\n",
      "Epoch: 49, train loss: 0.01213, test loss: 0.03510\n",
      "Epoch: 50\n",
      "Epoch: 50, train loss: 0.01179, test loss: 0.03513\n",
      "Epoch: 51\n",
      "Epoch: 51, train loss: 0.01204, test loss: 0.03510\n",
      "Epoch: 52\n",
      "Epoch: 52, train loss: 0.01227, test loss: 0.03512\n",
      "Epoch: 53\n",
      "Epoch: 53, train loss: 0.01198, test loss: 0.03511\n",
      "Epoch: 54\n",
      "Epoch: 54, train loss: 0.01212, test loss: 0.03511\n",
      "Epoch: 55\n",
      "Epoch: 55, train loss: 0.01214, test loss: 0.03511\n",
      "Epoch: 56\n",
      "Epoch: 56, train loss: 0.01192, test loss: 0.03511\n",
      "Epoch: 57\n",
      "Epoch: 57, train loss: 0.01278, test loss: 0.03523\n",
      "Epoch: 58\n",
      "Epoch: 58, train loss: 0.01250, test loss: 0.03516\n",
      "Epoch: 59\n",
      "Epoch: 59, train loss: 0.01198, test loss: 0.03511\n",
      "Epoch: 60\n",
      "Epoch: 60, train loss: 0.01204, test loss: 0.03510\n",
      "Epoch: 61\n",
      "Epoch: 61, train loss: 0.01240, test loss: 0.03514\n",
      "Epoch: 62\n",
      "Epoch: 62, train loss: 0.01181, test loss: 0.03513\n",
      "Epoch: 63\n",
      "Epoch: 63, train loss: 0.01242, test loss: 0.03514\n",
      "Epoch: 64\n",
      "Epoch: 64, train loss: 0.01174, test loss: 0.03516\n",
      "Epoch: 65\n",
      "Epoch: 65, train loss: 0.01219, test loss: 0.03511\n",
      "Epoch: 66\n",
      "Epoch: 66, train loss: 0.01182, test loss: 0.03514\n",
      "Epoch: 67\n",
      "Epoch: 67, train loss: 0.01178, test loss: 0.03514\n",
      "Epoch: 68\n",
      "Epoch: 68, train loss: 0.01207, test loss: 0.03510\n",
      "Epoch: 69\n",
      "Epoch: 69, train loss: 0.01213, test loss: 0.03510\n",
      "Epoch: 70\n",
      "Epoch: 70, train loss: 0.01177, test loss: 0.03514\n",
      "Epoch: 71\n",
      "Epoch: 71, train loss: 0.01200, test loss: 0.03510\n",
      "Epoch: 72\n",
      "Epoch: 72, train loss: 0.01211, test loss: 0.03510\n",
      "Epoch: 73\n",
      "Epoch: 73, train loss: 0.01235, test loss: 0.03513\n",
      "Epoch: 74\n",
      "Epoch: 74, train loss: 0.01220, test loss: 0.03511\n",
      "Epoch: 75\n",
      "Epoch: 75, train loss: 0.01214, test loss: 0.03511\n",
      "Epoch: 76\n",
      "Epoch: 76, train loss: 0.01211, test loss: 0.03510\n",
      "Epoch: 77\n",
      "Epoch: 77, train loss: 0.01211, test loss: 0.03510\n",
      "Epoch: 78\n",
      "Epoch: 78, train loss: 0.01194, test loss: 0.03511\n",
      "Epoch: 79\n",
      "Epoch: 79, train loss: 0.01251, test loss: 0.03516\n",
      "Epoch: 80\n",
      "Epoch: 80, train loss: 0.01207, test loss: 0.03510\n",
      "Epoch: 81\n",
      "Epoch: 81, train loss: 0.01226, test loss: 0.03512\n",
      "Epoch: 82\n",
      "Epoch: 82, train loss: 0.01170, test loss: 0.03517\n",
      "Epoch: 83\n",
      "Epoch: 83, train loss: 0.01204, test loss: 0.03510\n",
      "Epoch: 84\n",
      "Epoch: 84, train loss: 0.01226, test loss: 0.03512\n",
      "Epoch: 85\n",
      "Epoch: 85, train loss: 0.01221, test loss: 0.03511\n",
      "Epoch: 86\n",
      "Epoch: 86, train loss: 0.01262, test loss: 0.03519\n",
      "Epoch: 87\n",
      "Epoch: 87, train loss: 0.01201, test loss: 0.03510\n",
      "Epoch: 88\n",
      "Epoch: 88, train loss: 0.01229, test loss: 0.03512\n",
      "Epoch: 89\n",
      "Epoch: 89, train loss: 0.01191, test loss: 0.03511\n",
      "Epoch: 90\n",
      "Epoch: 90, train loss: 0.01227, test loss: 0.03512\n",
      "Epoch: 91\n",
      "Epoch: 91, train loss: 0.01169, test loss: 0.03517\n",
      "Epoch: 92\n",
      "Epoch: 92, train loss: 0.01208, test loss: 0.03511\n",
      "Epoch: 93\n",
      "Epoch: 93, train loss: 0.01186, test loss: 0.03512\n",
      "Epoch: 94\n",
      "Epoch: 94, train loss: 0.01204, test loss: 0.03510\n",
      "Epoch: 95\n",
      "Epoch: 95, train loss: 0.01229, test loss: 0.03512\n",
      "Epoch: 96\n",
      "Epoch: 96, train loss: 0.01211, test loss: 0.03510\n",
      "Epoch: 97\n",
      "Epoch: 97, train loss: 0.01219, test loss: 0.03511\n",
      "Epoch: 98\n",
      "Epoch: 98, train loss: 0.01179, test loss: 0.03514\n",
      "Epoch: 99\n",
      "Epoch: 99, train loss: 0.01180, test loss: 0.03513\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "n_epochs = 100\n",
    "\n",
    "prediction, result = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    nn=model, \n",
    "    optimiser=optimizer, \n",
    "    loss_fn=loss, \n",
    "    train_loader=train_loader, \n",
    "    test_loader=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

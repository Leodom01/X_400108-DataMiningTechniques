{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load users with searches and products\n",
    "df = pd.read_csv(\"./dataset/train_LFM.csv\")\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = train[:3000]\n",
    "test = test[:3000]\n",
    "#test = pd.read_csv(\"./dataset/test_LFM.csv\")\n",
    "\n",
    "# Warning, not using relevant information that is relevant only wrt search AND property together such as the distance user-property, or better price than competitor...\n",
    "# Not using: position, price_usd, orig_destination_distance, random_bool, booking_bool, comp_inv, comp_rate_percent_diff, interaction\n",
    "user_src_feats = [\n",
    "    \"site_id\", \"visitor_location_country_id\", \"srch_destination_id\", \n",
    "    \"srch_length_of_stay\", \"srch_adults_count\", \"srch_children_count\", \"srch_room_count\", \n",
    "    \"srch_saturday_night_bool\", #\"srch_query_affinity_score\"\n",
    "    ]\n",
    "prop_feats = [\"prop_country_id\", \"prop_starrating\", \"prop_review_score\", \n",
    "              \"prop_brand_bool\", \"prop_location_score1\", \"prop_location_score2\", \n",
    "              \"prop_log_historical_price\", \"price_usd\", \"promotion_flag\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_features(df):\n",
    "    train_prop_features = []\n",
    "    train_prop_ids = df[\"prop_id\"].unique()\n",
    "\n",
    "    for idx, prop_id in enumerate(train_prop_ids):\n",
    "        if idx%5000 == 0:\n",
    "            print(\"Prop percentage: \"+str(100*idx/len(train_prop_ids))+\"%\")\n",
    "\n",
    "        current_prop = df[df[\"prop_id\"] == prop_id]\n",
    "        features = {\n",
    "            \"prop_country_id\" : current_prop[\"prop_country_id\"].mean(),\n",
    "            \"prop_starrating\" : current_prop[\"prop_starrating\"].mean(),\n",
    "            \"prop_review_score\" : current_prop[\"prop_review_score\"].mean() if pd.notnull(current_prop[\"prop_review_score\"].mean()) else train[\"prop_review_score\"].mean(),\n",
    "            \"prop_brand_bool\" : current_prop[\"prop_brand_bool\"].mean(), \n",
    "            \"prop_location_score1\" : current_prop[\"prop_location_score1\"].mean(), \n",
    "            \"prop_location_score2\" : current_prop[\"prop_location_score2\"].mean() if pd.notnull(current_prop[\"prop_location_score2\"].mean()) else train[\"prop_location_score2\"].mean(),\n",
    "            \"prop_log_historical_price\" : current_prop[\"prop_log_historical_price\"].mean(), \n",
    "            \"price_usd\" : current_prop[\"price_usd\"].mean(), \n",
    "            \"promotion_flag\" : current_prop[\"promotion_flag\"].mean()\n",
    "        }\n",
    "        train_prop_features.append((prop_id, features))\n",
    "    return train_prop_features\n",
    "    \n",
    "def get_srch_features(df):\n",
    "    train_src_features = []\n",
    "    train_src_ids = df[\"srch_id\"].unique()\n",
    "\n",
    "    for idx, src_id in enumerate(train_src_ids):\n",
    "        if idx%5000 == 0:\n",
    "            print(\"Srch percentage: \"+str(100*idx/len(train_src_ids))+\"%\")\n",
    "\n",
    "        current_src = df[df[\"srch_id\"] == src_id]\n",
    "        features = {\n",
    "            \"visitor_location_country_id\" : current_src[\"visitor_location_country_id\"].iloc[0], \n",
    "            \"srch_destination_id\" : current_src[\"srch_destination_id\"].iloc[0],\n",
    "            \"srch_length_of_stay\" : current_src[\"srch_length_of_stay\"].iloc[0], \n",
    "            \"srch_adults_count\" : current_src[\"srch_adults_count\"].iloc[0], \n",
    "            \"srch_children_count\" : current_src[\"srch_children_count\"].iloc[0],\n",
    "            \"srch_room_count\" : current_src[\"srch_room_count\"].iloc[0], \n",
    "            \"srch_saturday_night_bool\" : current_src[\"srch_saturday_night_bool\"].iloc[0], \n",
    "            #\"srch_query_affinity_score\" : current_src[\"srch_query_affinity_score\"].iloc[0] if pd.notnull(current_src[\"srch_query_affinity_score\"].iloc[0]) else current_src[\"srch_query_affinity_score\"].mean()\n",
    "        }\n",
    "        train_src_features.append((src_id, features))\n",
    "    return train_src_features\n",
    "\n",
    "# Of course cannot be called since computes the available interaction, which is what we have to predict in the test dataset\n",
    "def get_interactions(df):\n",
    "    interaction_list = []\n",
    "    interaction_df = df.groupby([\"srch_id\", \"prop_id\"])[\"interaction\"].first().reset_index()\n",
    "    for tuple in interaction_df.itertuples():\n",
    "        interaction_list.append((tuple.srch_id, tuple.prop_id, tuple.interaction))\n",
    "    return interaction_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop percentage: 0.0%\n",
      "Prop features computed\n",
      "Srch percentage: 0.0%\n",
      "Srch features computed\n",
      "Interactions list computed\n"
     ]
    }
   ],
   "source": [
    "# Pack train set for training\n",
    "train_prop_features = get_prop_features(train)\n",
    "print(\"Prop features computed\")\n",
    "train_srch_features = get_srch_features(train)\n",
    "print(\"Srch features computed\")\n",
    "interaction_list = get_interactions(train)\n",
    "print(\"Interactions list computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop percentage: 0.0%\n",
      "Prop features computed\n",
      "Srch percentage: 0.0%\n",
      "Srch features computed\n"
     ]
    }
   ],
   "source": [
    "# Packing the test set for evaluation\n",
    "test_prop_features = get_prop_features(test)\n",
    "print(\"Prop features computed\")\n",
    "test_srch_features = get_srch_features(test)\n",
    "print(\"Srch features computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# Fit the dataset with user and item ids and features\n",
    "dataset.fit(\n",
    "    users=df[\"srch_id\"].unique(),\n",
    "    items=df[\"prop_id\"].unique(),\n",
    "    user_features=[\n",
    "        \"visitor_location_country_id\",\n",
    "        \"srch_destination_id\",\n",
    "        \"srch_length_of_stay\",\n",
    "        \"srch_adults_count\",\n",
    "        \"srch_children_count\",\n",
    "        \"srch_room_count\",\n",
    "        \"srch_saturday_night_bool\",\n",
    "        #\"srch_query_affinity_score\",\n",
    "    ],\n",
    "    item_features=[\n",
    "        \"prop_country_id\",\n",
    "        \"prop_starrating\",\n",
    "        \"prop_review_score\",\n",
    "        \"prop_brand_bool\",\n",
    "        \"prop_location_score1\",\n",
    "        \"prop_location_score2\",\n",
    "        \"prop_log_historical_price\",\n",
    "        \"price_usd\",\n",
    "        \"promotion_flag\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "(interactions, interactions_weights) = dataset.build_interactions(interaction_list)\n",
    "train_src_feat_matrix = dataset.build_user_features(train_srch_features)\n",
    "train_prop_feat_matrix = dataset.build_item_features(train_prop_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x17f041bb0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "latent_feats = 50\n",
    "training_epochs = 30\n",
    "\n",
    "model = LightFM(loss='warp', no_components=latent_feats)\n",
    "model.fit(interactions, user_features=train_src_feat_matrix, item_features=train_prop_feat_matrix, epochs=training_epochs, num_threads=8, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "0.03333333333333333%\n",
      "0.06666666666666667%\n",
      "0.1%\n",
      "0.13333333333333333%\n",
      "0.16666666666666666%\n",
      "0.2%\n",
      "0.23333333333333334%\n",
      "0.26666666666666666%\n",
      "0.3%\n",
      "0.3333333333333333%\n",
      "0.36666666666666664%\n",
      "0.4%\n",
      "0.43333333333333335%\n",
      "0.4666666666666667%\n",
      "0.5%\n",
      "0.5333333333333333%\n",
      "0.5666666666666667%\n",
      "0.6%\n",
      "0.6333333333333333%\n",
      "0.6666666666666666%\n",
      "0.7%\n",
      "0.7333333333333333%\n",
      "0.7666666666666667%\n",
      "0.8%\n",
      "0.8333333333333334%\n",
      "0.8666666666666667%\n",
      "0.9%\n",
      "0.9333333333333333%\n",
      "0.9666666666666667%\n",
      "Prediction features and ids ready\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Number of user feature rows does not equal the number of users",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m     srch_feats_matrix \u001b[38;5;241m=\u001b[39m tmp_dataset\u001b[38;5;241m.\u001b[39mbuild_user_features([srch_feats])\n\u001b[1;32m     72\u001b[0m     srch_prop_matrix \u001b[38;5;241m=\u001b[39m tmp_dataset\u001b[38;5;241m.\u001b[39mbuild_item_features([prop_feats])\n\u001b[0;32m---> 73\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msrch_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprop_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrch_feats_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrch_prop_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSrch ID: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(srch_id)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Prop ID: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(prop_id)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(prediction))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Predict the score\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#predictions = model.predict(np.array(srch_to_predict), np.array(prop_to_predict), \u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#                   user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/lightfm/lightfm.py:854\u001b[0m, in \u001b[0;36mLightFM.predict\u001b[0;34m(self, user_ids, item_ids, item_features, user_features, num_threads)\u001b[0m\n\u001b[1;32m    851\u001b[0m n_users \u001b[38;5;241m=\u001b[39m user_ids\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    852\u001b[0m n_items \u001b[38;5;241m=\u001b[39m item_ids\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 854\u001b[0m (user_features, item_features) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_feature_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m lightfm_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lightfm_data()\n\u001b[1;32m    860\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(user_ids), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/lightfm/lightfm.py:329\u001b[0m, in \u001b[0;36mLightFM._construct_feature_matrices\u001b[0;34m(self, n_users, n_items, user_features, item_features)\u001b[0m\n\u001b[1;32m    326\u001b[0m     item_features \u001b[38;5;241m=\u001b[39m item_features\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_users \u001b[38;5;241m>\u001b[39m user_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of user feature rows does not equal the number of users\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_items \u001b[38;5;241m>\u001b[39m item_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of item feature rows does not equal the number of items\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: Number of user feature rows does not equal the number of users"
     ]
    }
   ],
   "source": [
    "# Now to the prediction\n",
    "\n",
    "# Ensure user_ids and item_ids for the test set are available\n",
    "test_srch_ids = test[\"srch_id\"].unique()\n",
    "test_prop_ids = test[\"prop_id\"].unique()\n",
    "\n",
    "# test_src_feat_matrix = dataset.build_user_features(test_srch_features)\n",
    "# test_prop_feat_matrix = dataset.build_item_features(test_prop_features)\n",
    "# interactions, interaction_weights = dataset.build_interactions([])\n",
    "\n",
    "# model.fit_partial(interactions, user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix, epochs=training_epochs)\n",
    "\n",
    "srch_to_predict = []\n",
    "prop_to_predict = []\n",
    "prediction_srch_features = []\n",
    "prediction_prop_features = []\n",
    "\n",
    "# Get all the tuples of interactions to predict\n",
    "for idx, tup in enumerate(test.itertuples()):\n",
    "    if idx%100 == 0: \n",
    "        print(str(idx/len(test))+\"%\")\n",
    "\n",
    "    srch_to_predict.append(tup.srch_id)\n",
    "    for id, feats in test_srch_features:\n",
    "        if tup.srch_id == id:\n",
    "            prediction_srch_features.append((id, feats))\n",
    "            break\n",
    "\n",
    "    prop_to_predict.append(tup.prop_id)\n",
    "    for id, feats in test_prop_features:\n",
    "        if tup.prop_id == id:\n",
    "            prediction_prop_features.append((id, feats))\n",
    "            break\n",
    "\n",
    "print(\"Prediction features and ids ready\")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for srch_id, prop_id, srch_feats, prop_feats in zip(srch_to_predict, prop_to_predict, prediction_srch_features, prediction_prop_features):\n",
    "    ################\n",
    "    # Initialize the dataset\n",
    "    tmp_dataset = Dataset()\n",
    "\n",
    "    # Fit the dataset with user and item ids and features\n",
    "    tmp_dataset.fit(\n",
    "        users=[srch_id],\n",
    "        items=[prop_id],\n",
    "        user_features=[\n",
    "            \"visitor_location_country_id\",\n",
    "            \"srch_destination_id\",\n",
    "            \"srch_length_of_stay\",\n",
    "            \"srch_adults_count\",\n",
    "            \"srch_children_count\",\n",
    "            \"srch_room_count\",\n",
    "            \"srch_saturday_night_bool\",\n",
    "            #\"srch_query_affinity_score\",\n",
    "        ],\n",
    "        item_features=[\n",
    "            \"prop_country_id\",\n",
    "            \"prop_starrating\",\n",
    "            \"prop_review_score\",\n",
    "            \"prop_brand_bool\",\n",
    "            \"prop_location_score1\",\n",
    "            \"prop_location_score2\",\n",
    "            \"prop_log_historical_price\",\n",
    "            \"price_usd\",\n",
    "            \"promotion_flag\",\n",
    "        ],\n",
    "    )\n",
    "    ################\n",
    "    srch_feats_matrix = tmp_dataset.build_user_features([srch_feats])\n",
    "    srch_prop_matrix = tmp_dataset.build_item_features([prop_feats])\n",
    "    prediction = model.predict(user_ids=[srch_id], item_ids=[prop_id], user_features=srch_feats_matrix, item_features=srch_prop_matrix)\n",
    "    print(\"Srch ID: \"+str(srch_id)+\" Prop ID: \"+str(prop_id)+\"Prediction: \"+str(prediction))\n",
    "# Predict the score\n",
    "#predictions = model.predict(np.array(srch_to_predict), np.array(prop_to_predict), \n",
    "#                   user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# Loop through each user and item pair in the test set\n",
    "#for srch_id, prop_id in to_predict:\n",
    "#    # Ensure the user and item features are in the correct format\n",
    "#    for id, features in test_srch_features:\n",
    "#        if id == srch_id:\n",
    "#            srch_feats = list(features.values())\n",
    "#            break\n",
    "#\n",
    "#    for id, features in test_prop_features:\n",
    "#        if id == prop_id:\n",
    "#            prop_feats = list(features.values())\n",
    "#            break\n",
    "#    \n",
    "#    test_src_feat_matrix = dataset.build_user_features(test_srch_features)\n",
    "#    test_prop_feat_matrix = dataset.build_item_features(test_prop_features)\n",
    "#\n",
    "#    # Predict the score\n",
    "#    score = model.predict(np.array([srch_id]), np.array([prop_id]), \n",
    "#                          user_features=srch_feats, item_features=prop_feats)\n",
    "#    predictions.append((srch_id, prop_id, score[0]))\n",
    "#\n",
    "## Convert predictions to a DataFrame for easy viewing\n",
    "#predictions_df = pd.DataFrame(predictions, columns=[\"srch_id\", \"prop_id\", \"score\"])\n",
    "#\n",
    "## Save predictions to a CSV file\n",
    "#predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "#\n",
    "## Example: Display the first few predictions\n",
    "#print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Predicting the score for a user-item pair\n",
    "#user_id = 1\n",
    "#prop_id = 3309\n",
    "#\n",
    "#user_feats = None\n",
    "#for key, val in train_src_features:\n",
    "#    if key == user_id:\n",
    "#        user_feats = list(val.values())\n",
    "#        break\n",
    "#\n",
    "#prop_feats = None\n",
    "#for key, val in train_prop_features:\n",
    "#    if key == prop_id:\n",
    "#        prop_feats = list(val.values())\n",
    "#        break\n",
    "\n",
    "# Convert feature lists to sparse matrices\n",
    "# user_feats_matrix = csr_matrix(user_feats).reshape(1, -1)\n",
    "# prop_feats_matrix = csr_matrix(prop_feats).reshape(1, -1)\n",
    "\n",
    "#current_user_feats = [user_id, {\n",
    "#        \"visitor_location_country_id\":user_feats[0],\n",
    "#        \"srch_destination_id\":user_feats[1],\n",
    "#        \"srch_length_of_stay\":user_feats[2],\n",
    "#        \"srch_adults_count\":user_feats[3],\n",
    "#        \"srch_children_count\":user_feats[4],\n",
    "#        \"srch_room_count\":user_feats[5],\n",
    "#        \"srch_saturday_night_bool\":user_feats[6],\n",
    "#        #\"srch_query_affinity_score\",\n",
    "#    }]\n",
    "#current_user_feats = dataset.build_user_features([current_user_feats])\n",
    "\n",
    "#score = model.predict(user_ids=np.array([user_id]), item_ids=np.array([prop_id]), user_features=current_user_feats)\n",
    "#print(f\"Predicted score for user {user_id} and item {user_id}: {score[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating the model\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "\n",
    "train_precision = precision_at_k(model, interactions, k=5, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "train_auc = auc_score(model, interactions, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "\n",
    "print(f'Train precision at k: {train_precision:.2f}')\n",
    "print(f'Train AUC score: {train_auc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

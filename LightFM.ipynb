{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load users with searches and products\n",
    "df = pd.read_csv(\"./dataset/train_LFM.csv\")\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = train[:3000]\n",
    "test = test[:3000]\n",
    "#test = pd.read_csv(\"./dataset/test_LFM.csv\")\n",
    "\n",
    "# Warning, not using relevant information that is relevant only wrt search AND property together such as the distance user-property, or better price than competitor...\n",
    "# Not using: position, price_usd, orig_destination_distance, random_bool, booking_bool, comp_inv, comp_rate_percent_diff, interaction\n",
    "user_src_feats = [\n",
    "    \"site_id\", \"visitor_location_country_id\", \"srch_destination_id\", \n",
    "    \"srch_length_of_stay\", \"srch_adults_count\", \"srch_children_count\", \"srch_room_count\", \n",
    "    \"srch_saturday_night_bool\", #\"srch_query_affinity_score\"\n",
    "    ]\n",
    "prop_feats = [\"prop_country_id\", \"prop_starrating\", \"prop_review_score\", \n",
    "              \"prop_brand_bool\", \"prop_location_score1\", \"prop_location_score2\", \n",
    "              \"prop_log_historical_price\", \"price_usd\", \"promotion_flag\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_features(df):\n",
    "    train_prop_features = []\n",
    "    train_prop_ids = df[\"prop_id\"].unique()\n",
    "\n",
    "    for idx, prop_id in enumerate(train_prop_ids):\n",
    "        if idx%5000 == 0:\n",
    "            print(\"Prop percentage: \"+str(100*idx/len(train_prop_ids))+\"%\")\n",
    "\n",
    "        current_prop = df[df[\"prop_id\"] == prop_id]\n",
    "        features = {\n",
    "            \"prop_country_id\" : current_prop[\"prop_country_id\"].mean(),\n",
    "            \"prop_starrating\" : current_prop[\"prop_starrating\"].mean(),\n",
    "            \"prop_review_score\" : current_prop[\"prop_review_score\"].mean() if pd.notnull(current_prop[\"prop_review_score\"].mean()) else train[\"prop_review_score\"].mean(),\n",
    "            \"prop_brand_bool\" : current_prop[\"prop_brand_bool\"].mean(), \n",
    "            \"prop_location_score1\" : current_prop[\"prop_location_score1\"].mean(), \n",
    "            \"prop_location_score2\" : current_prop[\"prop_location_score2\"].mean() if pd.notnull(current_prop[\"prop_location_score2\"].mean()) else train[\"prop_location_score2\"].mean(),\n",
    "            \"prop_log_historical_price\" : current_prop[\"prop_log_historical_price\"].mean(), \n",
    "            \"price_usd\" : current_prop[\"price_usd\"].mean(), \n",
    "            \"promotion_flag\" : current_prop[\"promotion_flag\"].mean()\n",
    "        }\n",
    "        train_prop_features.append((prop_id, features))\n",
    "    return train_prop_features\n",
    "    \n",
    "def get_srch_features(df):\n",
    "    train_src_features = []\n",
    "    train_src_ids = df[\"srch_id\"].unique()\n",
    "\n",
    "    for idx, src_id in enumerate(train_src_ids):\n",
    "        if idx%5000 == 0:\n",
    "            print(\"Srch percentage: \"+str(100*idx/len(train_src_ids))+\"%\")\n",
    "\n",
    "        current_src = df[df[\"srch_id\"] == src_id]\n",
    "        features = {\n",
    "            \"visitor_location_country_id\" : current_src[\"visitor_location_country_id\"].iloc[0], \n",
    "            \"srch_destination_id\" : current_src[\"srch_destination_id\"].iloc[0],\n",
    "            \"srch_length_of_stay\" : current_src[\"srch_length_of_stay\"].iloc[0], \n",
    "            \"srch_adults_count\" : current_src[\"srch_adults_count\"].iloc[0], \n",
    "            \"srch_children_count\" : current_src[\"srch_children_count\"].iloc[0],\n",
    "            \"srch_room_count\" : current_src[\"srch_room_count\"].iloc[0], \n",
    "            \"srch_saturday_night_bool\" : current_src[\"srch_saturday_night_bool\"].iloc[0], \n",
    "            #\"srch_query_affinity_score\" : current_src[\"srch_query_affinity_score\"].iloc[0] if pd.notnull(current_src[\"srch_query_affinity_score\"].iloc[0]) else current_src[\"srch_query_affinity_score\"].mean()\n",
    "        }\n",
    "        train_src_features.append((src_id, features))\n",
    "    return train_src_features\n",
    "\n",
    "# Of course cannot be called since computes the available interaction, which is what we have to predict in the test dataset\n",
    "def get_interactions(df):\n",
    "    interaction_list = []\n",
    "    interaction_df = df.groupby([\"srch_id\", \"prop_id\"])[\"interaction\"].first().reset_index()\n",
    "    for tuple in interaction_df.itertuples():\n",
    "        interaction_list.append((tuple.srch_id, tuple.prop_id, tuple.interaction))\n",
    "    return interaction_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop percentage: 0.0%\n",
      "Prop features computed\n",
      "Srch percentage: 0.0%\n",
      "Srch features computed\n",
      "Interactions list computed\n"
     ]
    }
   ],
   "source": [
    "# Pack train set for training\n",
    "train_prop_features = get_prop_features(train)\n",
    "print(\"Prop features computed\")\n",
    "train_srch_features = get_srch_features(train)\n",
    "print(\"Srch features computed\")\n",
    "interaction_list = get_interactions(train)\n",
    "print(\"Interactions list computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop percentage: 0.0%\n",
      "Prop features computed\n",
      "Srch percentage: 0.0%\n",
      "Srch features computed\n"
     ]
    }
   ],
   "source": [
    "# Packing the test set for evaluation\n",
    "test_prop_features = get_prop_features(test)\n",
    "print(\"Prop features computed\")\n",
    "test_srch_features = get_srch_features(test)\n",
    "print(\"Srch features computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# Fit the dataset with user and item ids and features\n",
    "dataset.fit(\n",
    "    users=df[\"srch_id\"].unique(),\n",
    "    items=df[\"prop_id\"].unique(),\n",
    "    user_features=[\n",
    "        \"visitor_location_country_id\",\n",
    "        \"srch_destination_id\",\n",
    "        \"srch_length_of_stay\",\n",
    "        \"srch_adults_count\",\n",
    "        \"srch_children_count\",\n",
    "        \"srch_room_count\",\n",
    "        \"srch_saturday_night_bool\",\n",
    "        #\"srch_query_affinity_score\",\n",
    "    ],\n",
    "    item_features=[\n",
    "        \"prop_country_id\",\n",
    "        \"prop_starrating\",\n",
    "        \"prop_review_score\",\n",
    "        \"prop_brand_bool\",\n",
    "        \"prop_location_score1\",\n",
    "        \"prop_location_score2\",\n",
    "        \"prop_log_historical_price\",\n",
    "        \"price_usd\",\n",
    "        \"promotion_flag\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "(interactions, interactions_weights) = dataset.build_interactions(interaction_list)\n",
    "train_src_feat_matrix = dataset.build_user_features(train_srch_features)\n",
    "train_prop_feat_matrix = dataset.build_item_features(train_prop_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x35266a3d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "latent_feats = 50\n",
    "training_epochs = 30\n",
    "\n",
    "model = LightFM(loss='warp', no_components=latent_feats)\n",
    "model.fit(interactions, user_features=train_src_feat_matrix, item_features=train_prop_feat_matrix, epochs=training_epochs, num_threads=8, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "0.03333333333333333%\n",
      "0.06666666666666667%\n",
      "0.1%\n",
      "0.13333333333333333%\n",
      "0.16666666666666666%\n",
      "0.2%\n",
      "0.23333333333333334%\n",
      "0.26666666666666666%\n",
      "0.3%\n",
      "0.3333333333333333%\n",
      "0.36666666666666664%\n",
      "0.4%\n",
      "0.43333333333333335%\n",
      "0.4666666666666667%\n",
      "0.5%\n",
      "0.5333333333333333%\n",
      "0.5666666666666667%\n",
      "0.6%\n",
      "0.6333333333333333%\n",
      "0.6666666666666666%\n",
      "0.7%\n",
      "0.7333333333333333%\n",
      "0.7666666666666667%\n",
      "0.8%\n",
      "0.8333333333333334%\n",
      "0.8666666666666667%\n",
      "0.9%\n",
      "0.9333333333333333%\n",
      "0.9666666666666667%\n",
      "Prediction features and ids ready\n"
     ]
    }
   ],
   "source": [
    "# Now to the prediction\n",
    "\n",
    "# Ensure user_ids and item_ids for the test set are available\n",
    "test_srch_ids = test[\"srch_id\"].unique()\n",
    "test_prop_ids = test[\"prop_id\"].unique()\n",
    "\n",
    "# test_src_feat_matrix = dataset.build_user_features(test_srch_features)\n",
    "# test_prop_feat_matrix = dataset.build_item_features(test_prop_features)\n",
    "# interactions, interaction_weights = dataset.build_interactions([])\n",
    "\n",
    "# model.fit_partial(interactions, user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix, epochs=training_epochs)\n",
    "\n",
    "srch_to_predict = []\n",
    "prop_to_predict = []\n",
    "prediction_srch_features = []\n",
    "prediction_prop_features = []\n",
    "\n",
    "# Get all the tuples of interactions to predict\n",
    "for idx, tup in enumerate(test.itertuples()):\n",
    "    if idx%100 == 0: \n",
    "        print(str(idx/len(test))+\"%\")\n",
    "\n",
    "    srch_to_predict.append(tup.srch_id)\n",
    "    for id, feats in test_srch_features:\n",
    "        if tup.srch_id == id:\n",
    "            prediction_srch_features.append((id, feats))\n",
    "            break\n",
    "\n",
    "    prop_to_predict.append(tup.prop_id)\n",
    "    for id, feats in test_prop_features:\n",
    "        if tup.prop_id == id:\n",
    "            prediction_prop_features.append((id, feats))\n",
    "            break\n",
    "\n",
    "print(\"Prediction features and ids ready\")\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "# Initialize the dataset\n",
    "tmp_dataset = Dataset()\n",
    "\n",
    "# Fit the dataset with user and item ids and features\n",
    "tmp_dataset.fit(\n",
    "    users=test_srch_ids,\n",
    "    items=test_prop_ids,\n",
    "    user_features=[\n",
    "        \"visitor_location_country_id\",\n",
    "        \"srch_destination_id\",\n",
    "        \"srch_length_of_stay\",\n",
    "        \"srch_adults_count\",\n",
    "        \"srch_children_count\",\n",
    "        \"srch_room_count\",\n",
    "        \"srch_saturday_night_bool\",\n",
    "        #\"srch_query_affinity_score\",\n",
    "    ],\n",
    "    item_features=[\n",
    "        \"prop_country_id\",\n",
    "        \"prop_starrating\",\n",
    "        \"prop_review_score\",\n",
    "        \"prop_brand_bool\",\n",
    "        \"prop_location_score1\",\n",
    "        \"prop_location_score2\",\n",
    "        \"prop_log_historical_price\",\n",
    "        \"price_usd\",\n",
    "        \"promotion_flag\",\n",
    "    ],\n",
    ")\n",
    "################\n",
    "\n",
    "test_src_feat_matrix = tmp_dataset.build_user_features(prediction_srch_features)\n",
    "test_prop_feat_matrix = tmp_dataset.build_item_features(prediction_prop_features)\n",
    "\n",
    "# Predict the score\n",
    "predictions = model.predict(np.array(srch_to_predict), np.array(prop_to_predict), \n",
    "                    user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# Loop through each user and item pair in the test set\n",
    "#for srch_id, prop_id in to_predict:\n",
    "#    # Ensure the user and item features are in the correct format\n",
    "#    for id, features in test_srch_features:\n",
    "#        if id == srch_id:\n",
    "#            srch_feats = list(features.values())\n",
    "#            break\n",
    "#\n",
    "#    for id, features in test_prop_features:\n",
    "#        if id == prop_id:\n",
    "#            prop_feats = list(features.values())\n",
    "#            break\n",
    "#    \n",
    "#    test_src_feat_matrix = dataset.build_user_features(test_srch_features)\n",
    "#    test_prop_feat_matrix = dataset.build_item_features(test_prop_features)\n",
    "#\n",
    "#    # Predict the score\n",
    "#    score = model.predict(np.array([srch_id]), np.array([prop_id]), \n",
    "#                          user_features=srch_feats, item_features=prop_feats)\n",
    "#    predictions.append((srch_id, prop_id, score[0]))\n",
    "#\n",
    "## Convert predictions to a DataFrame for easy viewing\n",
    "#predictions_df = pd.DataFrame(predictions, columns=[\"srch_id\", \"prop_id\", \"score\"])\n",
    "#\n",
    "## Save predictions to a CSV file\n",
    "#predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "#\n",
    "## Example: Display the first few predictions\n",
    "#print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Predicting the score for a user-item pair\n",
    "#user_id = 1\n",
    "#prop_id = 3309\n",
    "#\n",
    "#user_feats = None\n",
    "#for key, val in train_src_features:\n",
    "#    if key == user_id:\n",
    "#        user_feats = list(val.values())\n",
    "#        break\n",
    "#\n",
    "#prop_feats = None\n",
    "#for key, val in train_prop_features:\n",
    "#    if key == prop_id:\n",
    "#        prop_feats = list(val.values())\n",
    "#        break\n",
    "\n",
    "# Convert feature lists to sparse matrices\n",
    "# user_feats_matrix = csr_matrix(user_feats).reshape(1, -1)\n",
    "# prop_feats_matrix = csr_matrix(prop_feats).reshape(1, -1)\n",
    "\n",
    "#current_user_feats = [user_id, {\n",
    "#        \"visitor_location_country_id\":user_feats[0],\n",
    "#        \"srch_destination_id\":user_feats[1],\n",
    "#        \"srch_length_of_stay\":user_feats[2],\n",
    "#        \"srch_adults_count\":user_feats[3],\n",
    "#        \"srch_children_count\":user_feats[4],\n",
    "#        \"srch_room_count\":user_feats[5],\n",
    "#        \"srch_saturday_night_bool\":user_feats[6],\n",
    "#        #\"srch_query_affinity_score\",\n",
    "#    }]\n",
    "#current_user_feats = dataset.build_user_features([current_user_feats])\n",
    "\n",
    "#score = model.predict(user_ids=np.array([user_id]), item_ids=np.array([prop_id]), user_features=current_user_feats)\n",
    "#print(f\"Predicted score for user {user_id} and item {user_id}: {score[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating the model\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "\n",
    "train_precision = precision_at_k(model, interactions, k=5, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "train_auc = auc_score(model, interactions, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "\n",
    "print(f'Train precision at k: {train_precision:.2f}')\n",
    "print(f'Train AUC score: {train_auc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load users with searches and products\n",
    "df = pd.read_csv(\"./dataset/train_LFM.csv\")[:6000]\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = train\n",
    "test = test\n",
    "#test = pd.read_csv(\"./dataset/test_LFM.csv\")\n",
    "\n",
    "# Warning, not using relevant information that is relevant only wrt search AND property together such as the distance user-property, or better price than competitor...\n",
    "# Not using: position, price_usd, orig_destination_distance, random_bool, booking_bool, comp_inv, comp_rate_percent_diff, interaction\n",
    "user_src_feats = [\n",
    "    \"site_id\", \"visitor_location_country_id\", \"srch_destination_id\", \n",
    "    \"srch_length_of_stay\", \"srch_adults_count\", \"srch_children_count\", \"srch_room_count\", \n",
    "    \"srch_saturday_night_bool\", #\"srch_query_affinity_score\"\n",
    "    ]\n",
    "prop_feats = [\"prop_country_id\", \"prop_starrating\", \"prop_review_score\", \n",
    "              \"prop_brand_bool\", \"prop_location_score1\", \"prop_location_score2\", \n",
    "              \"prop_log_historical_price\", \"price_usd\", \"promotion_flag\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_features(df):\n",
    "    train_prop_features = []\n",
    "    train_prop_ids = df[\"prop_id\"].unique()\n",
    "\n",
    "    for idx, prop_id in enumerate(train_prop_ids):\n",
    "        if idx%5000 == 0:\n",
    "            print(\"Prop percentage: \"+str(100*idx/len(train_prop_ids))+\"%\")\n",
    "\n",
    "        current_prop = df[df[\"prop_id\"] == prop_id]\n",
    "        features = {\n",
    "            \"prop_country_id\" : current_prop[\"prop_country_id\"].mean(),\n",
    "            \"prop_starrating\" : current_prop[\"prop_starrating\"].mean(),\n",
    "            \"prop_review_score\" : current_prop[\"prop_review_score\"].mean() if pd.notnull(current_prop[\"prop_review_score\"].mean()) else train[\"prop_review_score\"].mean(),\n",
    "            \"prop_brand_bool\" : current_prop[\"prop_brand_bool\"].mean(), \n",
    "            \"prop_location_score1\" : current_prop[\"prop_location_score1\"].mean(), \n",
    "            \"prop_location_score2\" : current_prop[\"prop_location_score2\"].mean() if pd.notnull(current_prop[\"prop_location_score2\"].mean()) else train[\"prop_location_score2\"].mean(),\n",
    "            \"prop_log_historical_price\" : current_prop[\"prop_log_historical_price\"].mean(), \n",
    "            \"price_usd\" : current_prop[\"price_usd\"].mean(), \n",
    "            \"promotion_flag\" : current_prop[\"promotion_flag\"].mean()\n",
    "        }\n",
    "        train_prop_features.append((prop_id, features))\n",
    "    return train_prop_features\n",
    "    \n",
    "def get_srch_features(df):\n",
    "    train_src_features = []\n",
    "    train_src_ids = df[\"srch_id\"].unique()\n",
    "\n",
    "    for idx, src_id in enumerate(train_src_ids):\n",
    "        if idx%5000 == 0:\n",
    "            print(\"Srch percentage: \"+str(100*idx/len(train_src_ids))+\"%\")\n",
    "\n",
    "        current_src = df[df[\"srch_id\"] == src_id]\n",
    "        features = {\n",
    "            \"visitor_location_country_id\" : current_src[\"visitor_location_country_id\"].iloc[0], \n",
    "            \"srch_destination_id\" : current_src[\"srch_destination_id\"].iloc[0],\n",
    "            \"srch_length_of_stay\" : current_src[\"srch_length_of_stay\"].iloc[0], \n",
    "            \"srch_adults_count\" : current_src[\"srch_adults_count\"].iloc[0], \n",
    "            \"srch_children_count\" : current_src[\"srch_children_count\"].iloc[0],\n",
    "            \"srch_room_count\" : current_src[\"srch_room_count\"].iloc[0], \n",
    "            \"srch_saturday_night_bool\" : current_src[\"srch_saturday_night_bool\"].iloc[0], \n",
    "            #\"srch_query_affinity_score\" : current_src[\"srch_query_affinity_score\"].iloc[0] if pd.notnull(current_src[\"srch_query_affinity_score\"].iloc[0]) else current_src[\"srch_query_affinity_score\"].mean()\n",
    "        }\n",
    "        train_src_features.append((src_id, features))\n",
    "    return train_src_features\n",
    "\n",
    "# Of course cannot be called since computes the available interaction, which is what we have to predict in the test dataset\n",
    "def get_interactions(df):\n",
    "    interaction_list = []\n",
    "    interaction_df = df.groupby([\"srch_id\", \"prop_id\"])[\"interaction\"].first().reset_index()\n",
    "    for tuple in interaction_df.itertuples():\n",
    "        interaction_list.append((tuple.srch_id, tuple.prop_id, tuple.interaction))\n",
    "    return interaction_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop percentage: 0.0%\n",
      "Prop percentage: 93.00595238095238%\n",
      "Prop features computed\n",
      "Srch percentage: 0.0%\n",
      "Srch features computed\n",
      "Interactions list computed\n"
     ]
    }
   ],
   "source": [
    "# Pack train set for training\n",
    "prop_features = get_prop_features(df)\n",
    "print(\"Prop features computed\")\n",
    "srch_features = get_srch_features(df)\n",
    "print(\"Srch features computed\")\n",
    "interaction_list = get_interactions(train)\n",
    "print(\"Interactions list computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m srch_feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, features \u001b[38;5;129;01min\u001b[39;00m srch_features:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43msrch_feature_names\u001b[49m\u001b[38;5;241m.\u001b[39mupdate(features\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      6\u001b[0m prop_feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, features \u001b[38;5;129;01min\u001b[39;00m prop_features:\n",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m srch_feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, features \u001b[38;5;129;01min\u001b[39;00m srch_features:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43msrch_feature_names\u001b[49m\u001b[38;5;241m.\u001b[39mupdate(features\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      6\u001b[0m prop_feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, features \u001b[38;5;129;01min\u001b[39;00m prop_features:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract feature names\n",
    "srch_feature_names = set()\n",
    "for _, features in srch_features:\n",
    "    srch_feature_names.update(features.keys())\n",
    "\n",
    "prop_feature_names = set()\n",
    "for _, features in prop_features:\n",
    "    prop_feature_names.update(features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m (interactions, interactions_weights) \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_interactions(interaction_list)\n\u001b[1;32m     32\u001b[0m src_feat_matrix \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_user_features(srch_features)\n\u001b[0;32m---> 33\u001b[0m prop_feat_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mbuild_item_features(prop_features)\n",
      "Cell \u001b[0;32mIn[39], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m (interactions, interactions_weights) \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_interactions(interaction_list)\n\u001b[1;32m     32\u001b[0m src_feat_matrix \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_user_features(srch_features)\n\u001b[0;32m---> 33\u001b[0m prop_feat_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mbuild_item_features(prop_features)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# Fit the dataset with user and item ids and features\n",
    "dataset.fit(\n",
    "    users=df[\"srch_id\"].unique(),\n",
    "    items=df[\"prop_id\"].unique(),\n",
    "    user_features=[\n",
    "        \"visitor_location_country_id\",\n",
    "        \"srch_destination_id\",\n",
    "        \"srch_length_of_stay\",\n",
    "        \"srch_adults_count\",\n",
    "        \"srch_children_count\",\n",
    "        \"srch_room_count\",\n",
    "        \"srch_saturday_night_bool\",\n",
    "        #\"srch_query_affinity_score\",\n",
    "    ],\n",
    "    item_features=[\n",
    "        \"prop_country_id\",\n",
    "        \"prop_starrating\",\n",
    "        \"prop_review_score\",\n",
    "        \"prop_brand_bool\",\n",
    "        \"prop_location_score1\",\n",
    "        \"prop_location_score2\",\n",
    "        \"prop_log_historical_price\",\n",
    "        \"price_usd\",\n",
    "        \"promotion_flag\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "(interactions, interactions_weights) = dataset.build_interactions(interaction_list)\n",
    "src_feat_matrix = dataset.build_user_features(srch_features)\n",
    "prop_feat_matrix = dataset.build_item_features(prop_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x17fc07ac0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "latent_feats = 50\n",
    "training_epochs = 30\n",
    "\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(interactions, user_features=src_feat_matrix, item_features=prop_feat_matrix, epochs=training_epochs, num_threads=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "8.333333333333334%\n",
      "16.666666666666668%\n",
      "25.0%\n",
      "33.333333333333336%\n",
      "41.666666666666664%\n",
      "50.0%\n",
      "58.333333333333336%\n",
      "66.66666666666667%\n",
      "75.0%\n",
      "83.33333333333333%\n",
      "91.66666666666667%\n",
      "Prediction features and ids ready\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Number of item feature rows does not equal the number of items",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 37\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# for id, feats in test_prop_features:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m#     if tup.prop_id == id:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#         prediction_prop_features.append((id, feats))\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#         break\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction features and ids ready\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m158\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m13878\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_feat_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprop_feat_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Predict the score\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#predictions = model.predict(np.array(srch_to_predict), np.array(prop_to_predict), \u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#                   user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/lightfm/lightfm.py:854\u001b[0m, in \u001b[0;36mLightFM.predict\u001b[0;34m(self, user_ids, item_ids, item_features, user_features, num_threads)\u001b[0m\n\u001b[1;32m    851\u001b[0m n_users \u001b[38;5;241m=\u001b[39m user_ids\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    852\u001b[0m n_items \u001b[38;5;241m=\u001b[39m item_ids\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 854\u001b[0m (user_features, item_features) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_feature_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m lightfm_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lightfm_data()\n\u001b[1;32m    860\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(user_ids), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/lightfm/lightfm.py:334\u001b[0m, in \u001b[0;36mLightFM._construct_feature_matrices\u001b[0;34m(self, n_users, n_items, user_features, item_features)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of user feature rows does not equal the number of users\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_items \u001b[38;5;241m>\u001b[39m item_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of item feature rows does not equal the number of items\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m     )\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# If we already have embeddings, verify that\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# we have them for all the supplied features\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mException\u001b[0m: Number of item feature rows does not equal the number of items"
     ]
    }
   ],
   "source": [
    "# Now to the prediction\n",
    "\n",
    "# Ensure user_ids and item_ids for the test set are available\n",
    "test_srch_ids = test[\"srch_id\"].unique()\n",
    "test_prop_ids = test[\"prop_id\"].unique()\n",
    "\n",
    "# test_src_feat_matrix = dataset.build_user_features(test_srch_features)\n",
    "# test_prop_feat_matrix = dataset.build_item_features(test_prop_features)\n",
    "# interactions, interaction_weights = dataset.build_interactions([])\n",
    "\n",
    "# model.fit_partial(interactions, user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix, epochs=training_epochs)\n",
    "\n",
    "srch_to_predict = []\n",
    "prop_to_predict = []\n",
    "# prediction_srch_features = []\n",
    "# prediction_prop_features = []\n",
    "\n",
    "# Get all the tuples of interactions to predict\n",
    "for idx, tup in enumerate(test.itertuples()):\n",
    "    if idx%100 == 0: \n",
    "        print(str(100*idx/len(test))+\"%\")\n",
    "\n",
    "    srch_to_predict.append(tup.srch_id)\n",
    "    # for id, feats in test_srch_features:\n",
    "    #     if tup.srch_id == id:\n",
    "    #         prediction_srch_features.append((id, feats))\n",
    "    #         break\n",
    "\n",
    "    prop_to_predict.append(tup.prop_id)\n",
    "    # for id, feats in test_prop_features:\n",
    "    #     if tup.prop_id == id:\n",
    "    #         prediction_prop_features.append((id, feats))\n",
    "    #         break\n",
    "\n",
    "print(\"Prediction features and ids ready\")\n",
    "\n",
    "predictions = model.predict(np.array([158]), np.array([13878]), user_features=src_feat_matrix, item_features=prop_feat_matrix)\n",
    "\n",
    "# Predict the score\n",
    "#predictions = model.predict(np.array(srch_to_predict), np.array(prop_to_predict), \n",
    "#                   user_features=test_src_feat_matrix, item_features=test_prop_feat_matrix)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# Loop through each user and item pair in the test set\n",
    "#for srch_id, prop_id in to_predict:\n",
    "#    # Ensure the user and item features are in the correct format\n",
    "#    for id, features in test_srch_features:\n",
    "#        if id == srch_id:\n",
    "#            srch_feats = list(features.values())\n",
    "#            break\n",
    "#\n",
    "#    for id, features in test_prop_features:\n",
    "#        if id == prop_id:\n",
    "#            prop_feats = list(features.values())\n",
    "#            break\n",
    "#    \n",
    "#    test_src_feat_matrix = dataset.build_user_features(test_srch_features)\n",
    "#    test_prop_feat_matrix = dataset.build_item_features(test_prop_features)\n",
    "#\n",
    "#    # Predict the score\n",
    "#    score = model.predict(np.array([srch_id]), np.array([prop_id]), \n",
    "#                          user_features=srch_feats, item_features=prop_feats)\n",
    "#    predictions.append((srch_id, prop_id, score[0]))\n",
    "#\n",
    "## Convert predictions to a DataFrame for easy viewing\n",
    "#predictions_df = pd.DataFrame(predictions, columns=[\"srch_id\", \"prop_id\", \"score\"])\n",
    "#\n",
    "## Save predictions to a CSV file\n",
    "#predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "#\n",
    "## Example: Display the first few predictions\n",
    "#print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating the model\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "\n",
    "train_precision = precision_at_k(model, interactions, k=5, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "train_auc = auc_score(model, interactions, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "\n",
    "print(f'Train precision at k: {train_precision:.2f}')\n",
    "print(f'Train AUC score: {train_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Fit the dataset with user and item ids and all possible feature names\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     52\u001b[0m     users\u001b[38;5;241m=\u001b[39musers,\n\u001b[1;32m     53\u001b[0m     items\u001b[38;5;241m=\u001b[39mitems,\n\u001b[1;32m     54\u001b[0m     user_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m)],\n\u001b[1;32m     55\u001b[0m     item_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopularity:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)]\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Build the interactions matrix\u001b[39;00m\n\u001b[1;32m     59\u001b[0m (interactions, weights) \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_interactions([(x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m], x[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m interactions])\n",
      "Cell \u001b[0;32mIn[52], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Fit the dataset with user and item ids and all possible feature names\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     52\u001b[0m     users\u001b[38;5;241m=\u001b[39musers,\n\u001b[1;32m     53\u001b[0m     items\u001b[38;5;241m=\u001b[39mitems,\n\u001b[1;32m     54\u001b[0m     user_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m)],\n\u001b[1;32m     55\u001b[0m     item_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopularity:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)]\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Build the interactions matrix\u001b[39;00m\n\u001b[1;32m     59\u001b[0m (interactions, weights) \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_interactions([(x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m], x[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m interactions])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Example data\n",
    "users = [1, 2, 3, 4]\n",
    "items = [1, 2, 3, 4, 5]\n",
    "interactions = [\n",
    "    (1, 1, 1.0),\n",
    "    (1, 2, 1.0),\n",
    "    (2, 2, 1.0),\n",
    "    (2, 3, 1.0),\n",
    "    (3, 3, 1.0),\n",
    "    (3, 4, 1.0),\n",
    "    (4, 4, 1.0),\n",
    "    (4, 5, 1.0)\n",
    "]\n",
    "\n",
    "user_features = {\n",
    "    1: {\"age\": 23, \"income\": 50000},\n",
    "    2: {\"age\": 45, \"income\": 70000},\n",
    "    3: {\"age\": 34, \"income\": 65000},\n",
    "    4: {\"age\": 28, \"income\": 48000}\n",
    "}\n",
    "\n",
    "item_features = {\n",
    "    1: {\"price\": 20.0, \"popularity\": 0.9},\n",
    "    2: {\"price\": 35.0, \"popularity\": 0.7},\n",
    "    3: {\"price\": 50.0, \"popularity\": 0.8},\n",
    "    4: {\"price\": 15.0, \"popularity\": 0.6},\n",
    "    5: {\"price\": 45.0, \"popularity\": 0.9}\n",
    "}\n",
    "\n",
    "# Convert user and item features to lists of tuples with proper formatting\n",
    "user_features_list = [(user, [f\"age:{feature_dict['age']}\", f\"income:{feature_dict['income']}\"]) for user, feature_dict in user_features.items()]\n",
    "item_features_list = [(item, [f\"price:{feature_dict['price']}\", f\"popularity:{feature_dict['popularity']}\"]) for item, feature_dict in item_features.items()]\n",
    "\n",
    "# Extract feature names\n",
    "user_feature_names = set()\n",
    "for features in user_features.values():\n",
    "    user_feature_names.update(features.keys())\n",
    "\n",
    "item_feature_names = set()\n",
    "for features in item_features.values():\n",
    "    item_feature_names.update(features.keys())\n",
    "# Initialize the dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# Fit the dataset with user and item ids and all possible feature names\n",
    "dataset.fit(\n",
    "    users=users,\n",
    "    items=items,\n",
    "    user_features=[f\"age:{i}\" for i in range(100)] + [f\"income:{i}\" for i in range(100000)],\n",
    "    item_features=[f\"price:{i:.1f}\" for i in np.arange(0, 100, 0.1)] + [f\"popularity:{i:.1f}\" for i in np.arange(0, 1.1, 0.1)]\n",
    ")\n",
    "\n",
    "# Build the interactions matrix\n",
    "(interactions, weights) = dataset.build_interactions([(x[0], x[1], x[2]) for x in interactions])\n",
    "\n",
    "# Build the user and item features matrices\n",
    "user_features_matrix = dataset.build_user_features(user_features_list)\n",
    "item_features_matrix = dataset.build_item_features(item_features_list)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(interactions, user_features=user_features_matrix, item_features=item_features_matrix, epochs=30, num_threads=2)\n",
    "\n",
    "# Predicting the score for a user-item pair\n",
    "user_id = 1\n",
    "item_id = 3\n",
    "score = model.predict(np.array([user_id]), np.array([item_id]), user_features=user_features_matrix, item_features=item_features_matrix)\n",
    "print(f\"Predicted score for user {user_id} and item {item_id}: {score[0]}\")\n",
    "\n",
    "# Evaluation\n",
    "train_precision = precision_at_k(model, interactions, k=5, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "train_auc = auc_score(model, interactions, user_features=user_features_matrix, item_features=item_features_matrix).mean()\n",
    "\n",
    "print(f'Train precision at k: {train_precision:.2f}')\n",
    "print(f'Train AUC score: {train_auc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:19:45.439747Z",
     "start_time": "2024-05-23T23:19:21.587116Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('./dataset/training_set_VU_DM.csv')\n",
    "df_test = pd.read_csv('./dataset/test_set_VU_DM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1bd4c3f1fa97fb36"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df['target_label'] = 0\n",
    "\n",
    "# 5 - The user purchased a room at this hotel\n",
    "# 1 - The user clicked through to see more information on this hotel\n",
    "# 0 - The user neither clicked on this hotel nor purchased a room at this hotel\n",
    "df.loc[df['click_bool'] == 1, 'target_label'] = 1\n",
    "df.loc[df['booking_bool'] == 1, 'target_label'] = 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:19:45.478265Z",
     "start_time": "2024-05-23T23:19:45.438336Z"
    }
   },
   "id": "6f5399ee85b3b5c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dropping columns \n",
    "For starters, we can drop columns that do not provide valuable information or are missing a lot of values\n",
    "\n",
    "- Dropping the different company attribute since the majority of the values are missing, and they seem to provide little information (the only thing that comes to mind perhaps is if someone visits expedia, therefore, they trust the brand more, and thus seeing them having more expensive options would not change their mind... WAY too hard to capture... perhaps better to drop for now)\n",
    "- date_time: since no one cares about when search took place (might matter in some cases like trends and seasonality but will be also extremely hard to do)\n",
    "- gross_booking: since  our model should not care about how much they spent on the hotel, and only if they purchase or not\n",
    "- click_bool, booking_book: transformed into a relevant target_bool column\n",
    "- srch_affinity_score: I do not understand this attribute or how it's supposed to be relevant. Will remove now, revisit late \n",
    "- srch_booking_window: Irrelevant for ranking\n",
    "- prop_location_score2: missing 22%, seems very valuable, find suitable imputation method\n",
    "- 'orig_destination_distance', 'srch_query_affinity_score': LOTS of missing values, Might impute later to test\n",
    "- random_bool: an interesting attribute but fail to see its relevance, will revisit!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e43ff794c8d2a60"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "drop_columns_train = ['date_time', 'site_id', 'comp1_rate', 'comp1_inv',\n",
    "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
    "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
    "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
    "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
    "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
    "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
    "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
    "       'comp8_rate_percent_diff', 'click_bool', 'booking_bool', 'gross_bookings_usd', 'orig_destination_distance', 'random_bool']\n",
    "\n",
    "drop_columns_test = ['date_time', 'site_id', 'comp1_rate', 'comp1_inv',\n",
    "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
    "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
    "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
    "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
    "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
    "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
    "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
    "       'comp8_rate_percent_diff', 'orig_destination_distance', 'random_bool']\n",
    "\n",
    "\n",
    "df.drop(columns=drop_columns_train, inplace=True)\n",
    "df_test.drop(columns=drop_columns_test, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:19:45.967848Z",
     "start_time": "2024-05-23T23:19:45.472050Z"
    }
   },
   "id": "699f5df1041bf669"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experimenting with imputation\n",
    "User history rating, THE majority is null. Use mean imputation to fill these values. The idea is that the majority of the people will not rate too high or too low. \n",
    "Another approache besides mean imputation is to learn the distribution of the data (for example normal distribution for the average rating) and impute based on that, so it would retain it's normal distribution.... "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55ead9066b36ecd0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# for column in ['visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_review_score', 'prop_country_id']:\n",
    "#     mean_value = df[column].mean()\n",
    "#     df[column].fillna(mean_value, inplace=True)\n",
    "# \n",
    "# for column in ['visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_review_score', 'prop_country_id']:\n",
    "#     mean_value = df_test[column].mean()\n",
    "#     df_test[column].fillna(mean_value, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:19:45.971750Z",
     "start_time": "2024-05-23T23:19:45.969610Z"
    }
   },
   "id": "4da0439aacff9871"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f3b938d7a47aa84"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:19:45.974788Z",
     "start_time": "2024-05-23T23:19:45.971824Z"
    }
   },
   "id": "e878e4c17ddeb19b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Removing the unique identifiers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75e82f1dd2013396"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "unique_ids = ['visitor_location_country_id', 'srch_destination_id']\n",
    "\n",
    "df.drop(columns=unique_ids, inplace=True)\n",
    "df_test.drop(columns=unique_ids, inplace=True)\n",
    "\n",
    "df.to_csv(\"./dataset/train_clean_v1_noIDs.csv\", index=False)\n",
    "df_test.to_csv(\"./dataset/test_clean_v1_noIDs.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:20:21.670130Z",
     "start_time": "2024-05-23T23:19:45.975321Z"
    }
   },
   "id": "7e9d97a7a0496444"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aggregated features \n",
    "will try to aggregate some of the features, since it might be easier for the model to understand\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1789bed1650c3aa7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# aggregating the price of hotels over the entire timeline \n",
    "df['MEAN_price_per_prop'] = df.groupby('prop_id')['price_usd'].transform('mean')\n",
    "df['SUB_price_MEAN'] = df['price_usd'] - df['MEAN_price_per_prop']\n",
    "\n",
    "# aggregating the starrating of hotels per query, might be more interesting for model if positives show an above average hotel, etc...\n",
    "# MEAN_startrating_per_query = df.groupby('srch_id')['prop_starrating'].transform('mean')\n",
    "# df['SUB_starrating_MEAN'] = df['prop_starrating'] - MEAN_startrating_per_query\n",
    "\n",
    "# aggregating the starrating of hotels per query, might be more interesting for model if positives show an above average hotel, etc...\n",
    "MEAN_propscore2_per_query = df.groupby('srch_id')['prop_location_score2'].transform('mean')\n",
    "df['SUB_propscore2_MEAN'] = df['prop_location_score2'] - MEAN_propscore2_per_query\n",
    "\n",
    "\n",
    "df_test['MEAN_price_per_prop'] = df_test.groupby('prop_id')['price_usd'].transform('mean')\n",
    "\n",
    "# Step 2: Subtract the mean price from each price_usd\n",
    "df_test['SUB_price_MEAN'] = df_test['price_usd'] - df_test['MEAN_price_per_prop']\n",
    "\n",
    "# # Aggregating the starrating of hotels per query\n",
    "# MEAN_startrating_per_query = df_test.groupby('srch_id')['prop_starrating'].transform('mean')\n",
    "# df_test['SUB_starrating_MEAN'] = df_test['prop_starrating'] - MEAN_startrating_per_query\n",
    "\n",
    "# Aggregating the location score of hotels per query\n",
    "MEAN_propscore2_per_query = df_test.groupby('srch_id')['prop_location_score2'].transform('mean')\n",
    "df_test['SUB_propscore2_MEAN'] = df_test['prop_location_score2'] - MEAN_propscore2_per_query\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:20:22.295502Z",
     "start_time": "2024-05-23T23:20:21.673539Z"
    }
   },
   "id": "1dfb749ba1071817"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "         srch_id  visitor_hist_starrating  visitor_hist_adr_usd  \\\n0              1                      NaN                   NaN   \n1              1                      NaN                   NaN   \n2              1                      NaN                   NaN   \n3              1                      NaN                   NaN   \n4              1                      NaN                   NaN   \n...          ...                      ...                   ...   \n4958342   332785                      NaN                   NaN   \n4958343   332785                      NaN                   NaN   \n4958344   332785                      NaN                   NaN   \n4958345   332785                      NaN                   NaN   \n4958346   332785                      NaN                   NaN   \n\n         prop_country_id  prop_id  prop_starrating  prop_review_score  \\\n0                    219      893                3                3.5   \n1                    219    10404                4                4.0   \n2                    219    21315                3                4.5   \n3                    219    27348                2                4.0   \n4                    219    29604                4                3.5   \n...                  ...      ...              ...                ...   \n4958342              219    77700                3                4.0   \n4958343              219    88083                3                4.0   \n4958344              219    94508                3                3.5   \n4958345              219   128360                3                5.0   \n4958346              219   134949                3                2.5   \n\n         prop_brand_bool  prop_location_score1  prop_location_score2  ...  \\\n0                      1                  2.83                0.0438  ...   \n1                      1                  2.20                0.0149  ...   \n2                      1                  2.20                0.0245  ...   \n3                      1                  2.83                0.0125  ...   \n4                      1                  2.64                0.1241  ...   \n...                  ...                   ...                   ...  ...   \n4958342                1                  1.61                0.0471  ...   \n4958343                1                  1.95                0.1520  ...   \n4958344                1                  1.10                0.0164  ...   \n4958345                1                  1.95                0.0662  ...   \n4958346                1                  1.10                   NaN  ...   \n\n         srch_booking_window  srch_adults_count  srch_children_count  \\\n0                          0                  4                    0   \n1                          0                  4                    0   \n2                          0                  4                    0   \n3                          0                  4                    0   \n4                          0                  4                    0   \n...                      ...                ...                  ...   \n4958342                   21                  3                    0   \n4958343                   21                  3                    0   \n4958344                   21                  3                    0   \n4958345                   21                  3                    0   \n4958346                   21                  3                    0   \n\n         srch_room_count  srch_saturday_night_bool  srch_query_affinity_score  \\\n0                      1                         1                        NaN   \n1                      1                         1                        NaN   \n2                      1                         1                        NaN   \n3                      1                         1                        NaN   \n4                      1                         1                        NaN   \n...                  ...                       ...                        ...   \n4958342                1                         0                        NaN   \n4958343                1                         0                        NaN   \n4958344                1                         0                        NaN   \n4958345                1                         0                        NaN   \n4958346                1                         0                        NaN   \n\n         target_label  MEAN_price_per_prop  SUB_price_MEAN  \\\n0                   0           118.758742      -13.988742   \n1                   0           152.054082       18.685918   \n2                   0           168.540871       11.259129   \n3                   0            82.598870      520.171130   \n4                   0           137.648135        5.931865   \n...               ...                  ...             ...   \n4958342             0           131.241702      -13.241702   \n4958343             0            84.545789        4.454211   \n4958344             0           116.537209      -17.537209   \n4958345             5           150.336757      -11.336757   \n4958346             0            60.500000        0.500000   \n\n         SUB_propscore2_MEAN  \n0                  -0.005192  \n1                  -0.034092  \n2                  -0.024492  \n3                  -0.036492  \n4                   0.075108  \n...                      ...  \n4958342            -0.023325  \n4958343             0.081575  \n4958344            -0.054025  \n4958345            -0.004225  \n4958346                  NaN  \n\n[4958347 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>srch_id</th>\n      <th>visitor_hist_starrating</th>\n      <th>visitor_hist_adr_usd</th>\n      <th>prop_country_id</th>\n      <th>prop_id</th>\n      <th>prop_starrating</th>\n      <th>prop_review_score</th>\n      <th>prop_brand_bool</th>\n      <th>prop_location_score1</th>\n      <th>prop_location_score2</th>\n      <th>...</th>\n      <th>srch_booking_window</th>\n      <th>srch_adults_count</th>\n      <th>srch_children_count</th>\n      <th>srch_room_count</th>\n      <th>srch_saturday_night_bool</th>\n      <th>srch_query_affinity_score</th>\n      <th>target_label</th>\n      <th>MEAN_price_per_prop</th>\n      <th>SUB_price_MEAN</th>\n      <th>SUB_propscore2_MEAN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>893</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>2.83</td>\n      <td>0.0438</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>118.758742</td>\n      <td>-13.988742</td>\n      <td>-0.005192</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>10404</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>2.20</td>\n      <td>0.0149</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>152.054082</td>\n      <td>18.685918</td>\n      <td>-0.034092</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>21315</td>\n      <td>3</td>\n      <td>4.5</td>\n      <td>1</td>\n      <td>2.20</td>\n      <td>0.0245</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>168.540871</td>\n      <td>11.259129</td>\n      <td>-0.024492</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>27348</td>\n      <td>2</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>2.83</td>\n      <td>0.0125</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>82.598870</td>\n      <td>520.171130</td>\n      <td>-0.036492</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>29604</td>\n      <td>4</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>2.64</td>\n      <td>0.1241</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>137.648135</td>\n      <td>5.931865</td>\n      <td>0.075108</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4958342</th>\n      <td>332785</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>77700</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>1.61</td>\n      <td>0.0471</td>\n      <td>...</td>\n      <td>21</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>131.241702</td>\n      <td>-13.241702</td>\n      <td>-0.023325</td>\n    </tr>\n    <tr>\n      <th>4958343</th>\n      <td>332785</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>88083</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>1.95</td>\n      <td>0.1520</td>\n      <td>...</td>\n      <td>21</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>84.545789</td>\n      <td>4.454211</td>\n      <td>0.081575</td>\n    </tr>\n    <tr>\n      <th>4958344</th>\n      <td>332785</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>94508</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>1.10</td>\n      <td>0.0164</td>\n      <td>...</td>\n      <td>21</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>116.537209</td>\n      <td>-17.537209</td>\n      <td>-0.054025</td>\n    </tr>\n    <tr>\n      <th>4958345</th>\n      <td>332785</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>128360</td>\n      <td>3</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>1.95</td>\n      <td>0.0662</td>\n      <td>...</td>\n      <td>21</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>150.336757</td>\n      <td>-11.336757</td>\n      <td>-0.004225</td>\n    </tr>\n    <tr>\n      <th>4958346</th>\n      <td>332785</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>219</td>\n      <td>134949</td>\n      <td>3</td>\n      <td>2.5</td>\n      <td>1</td>\n      <td>1.10</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>21</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>60.500000</td>\n      <td>0.500000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4958347 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:20:23.921469Z",
     "start_time": "2024-05-23T23:20:22.374440Z"
    }
   },
   "id": "1b8ef7a94430a184"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8566f6c55b272ff8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.to_csv(\"./dataset/train_new_feature.csv\", index=False)\n",
    "df_test.to_csv(\"./dataset/test_new_feature.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:21:18.933140Z",
     "start_time": "2024-05-23T23:20:23.921590Z"
    }
   },
   "id": "3f4f9e30e5f8cb3f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T23:21:18.934281Z",
     "start_time": "2024-05-23T23:21:18.932375Z"
    }
   },
   "id": "14921c6202061f0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
